<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hexo">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-hashmap" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/10/01/hashmap/" class="article-date">
  <time datetime="2016-10-01T11:42:37.000Z" itemprop="datePublished">2016-10-01</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/10/01/hashmap/">hashmap</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/10/01/hashmap/" data-id="ciuakuqmi00006zonsa1v5my0" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-javaGC" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/09/13/javaGC/" class="article-date">
  <time datetime="2016-09-13T03:12:59.000Z" itemprop="datePublished">2016-09-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/09/13/javaGC/">GC调优</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="GC调优"><a href="#GC调优" class="headerlink" title="GC调优"></a>GC调优</h1><p>因为应用程序跑在jetty下，所以先说下启动jetty的jvm参数。</p>
<pre><code>java -XX:+CMSParallelRemarkEnabled -XX:+CMSScavengeBeforeRemark -XX:+ParallelRefProcEnabled -XX:+UseCMSInitiatingOccupancyOnly -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=50 -XX:CMSMaxAbortablePrecleanTime=6000 -XX:ConcGCThreads=4 -XX:MaxTenuringThreshold=8 -XX:NewRatio=3 -XX:ParallelGCThreads=4 -XX:PretenureSizeThreshold=64m -XX:SurvivorRatio=4 -XX:TargetSurvivorRatio=90 -Xmx75600m -Xms75600m -XX:ParallelGCThreads=4 -XX:+UseParNewGC -XX:+UseCompressedOops -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=8999 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -jar start.jar jetty.http.port=80
</code></pre><h2 id="GC目的"><a href="#GC目的" class="headerlink" title="GC目的"></a>GC目的</h2><p><em>GC的优化一般是最后一项任务</em>。</p>
<p>进行GC优化的目的一般有两个：</p>
<ul>
<li>将转移到老年代的对象数量降低到最少。</li>
<li>减少Full GC的时间。</li>
</ul>
<h2 id="GC优化需要考虑的Java参数"><a href="#GC优化需要考虑的Java参数" class="headerlink" title="GC优化需要考虑的Java参数"></a>GC优化需要考虑的Java参数</h2><table>
<thead>
<tr>
<th>定义</th>
<th>参数</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>堆内存空间</td>
<td>-Xms</td>
<td>Heap area size when starting JVM。启动JVM时的堆内存空间。</td>
</tr>
<tr>
<td></td>
<td>-Xmx</td>
<td>Maximum heap area size。堆内存最大限制。</td>
</tr>
<tr>
<td>新生代空间</td>
<td>-XX:NewRatio</td>
<td>Ratio of New area and Old area。新生代和老年代的占比。</td>
</tr>
<tr>
<td></td>
<td>-XX:NewSize</td>
<td>New area size。新生代空间</td>
</tr>
<tr>
<td></td>
<td>-XX:SurvivorRatio</td>
<td>Ratio ofEdenarea and Survivor area。伊甸园空间和幸存者空间的占比</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>GC分类</th>
<th>参数</th>
</tr>
</thead>
<tbody>
<tr>
<td>Serial GC</td>
<td>-XX:+UseSerialGC</td>
</tr>
<tr>
<td>Parallel GC</td>
<td>-XX:+UseParallelGC -XX:ParallelGCThreads=value</td>
</tr>
<tr>
<td>Parallel Compacting GC</td>
<td>-XX:+UseParallelOldGC</td>
</tr>
<tr>
<td>CMS GC</td>
<td>-XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:+CMSParallelRemarkEnabled -XX:CMSInitiatingOccupancyFraction=value -XX:+UseCMSInitiatingOccupancyOnly</td>
</tr>
<tr>
<td>G1</td>
<td>XX:+UnlockExperimentalVMOptions -XX:+UseG1GC</td>
</tr>
</tbody>
</table>
<ul>
<li>说明：如果NewRatio为2，意味着新生代老年代之比为1:2，因此该值越大，老年代空间越大，新生代空间越小。NewRatio参数会显著地影响整个GC的性能。如果新生代空间很小，会用更多的对象被转移到老年代空间，这样导致频繁的Full GC，增加暂停时间。</li>
</ul>
<h2 id="GC优化过程"><a href="#GC优化过程" class="headerlink" title="GC优化过程"></a>GC优化过程</h2><h3 id="监控GC状态"><a href="#监控GC状态" class="headerlink" title="监控GC状态"></a>监控GC状态</h3><ul>
<li><p>打印GC日志是很好的方式，因为记录GC日志并不会特别地影响java程序性能。</p>
<pre><code>-Xloggc:$CATALINA_BASE/logs/gc.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps。
</code></pre></li>
<li><p>监控jetty，可以通过jconsole来监控。</p>
</li>
<li><p>通过jstat来监控，比如：jstat -gc <vimid> 1000</vimid></p>
</li>
</ul>
<p>一般有两个重要指标：</p>
<ul>
<li><p>新生代GC平均时间：YGCT/YGC</p>
</li>
<li><p>老年代GC平均时间：FGCT/FGC</p>
</li>
</ul>
<p>关于jstat参数的说明如下：</p>
<table>
<thead>
<tr>
<th>列</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>S0C</td>
<td>输出Survivor0空间的大小。单位KB。</td>
</tr>
<tr>
<td>S1C</td>
<td>输出Survivor1空间的大小。单位KB。</td>
</tr>
<tr>
<td>S0U</td>
<td>输出Survivor0已用空间的大小。单位KB。</td>
</tr>
<tr>
<td>S1U</td>
<td>输出Survivor1已用空间的大小。单位KB。</td>
</tr>
<tr>
<td>EC</td>
<td>输出Eden空间的大小。单位KB。</td>
</tr>
<tr>
<td>EU</td>
<td>输出Eden已用空间的大小。单位KB。</td>
</tr>
<tr>
<td>OC</td>
<td>输出老年代空间的大小。单位KB。</td>
</tr>
<tr>
<td>OU</td>
<td>输出老年代已用空间的大小。单位KB。</td>
</tr>
<tr>
<td>PC</td>
<td>输出持久代空间的大小。单位KB。</td>
</tr>
<tr>
<td>PU</td>
<td>输出持久代已用空间的大小。单位KB。</td>
</tr>
<tr>
<td>YGC</td>
<td>新生代空间GC时间发生的次数。</td>
</tr>
<tr>
<td>YGCT</td>
<td>新生代GC处理花费的时间。</td>
</tr>
<tr>
<td>FGC</td>
<td>full GC发生的次数。</td>
</tr>
<tr>
<td>FGCT</td>
<td>full GC操作花费的时间</td>
</tr>
<tr>
<td>GCT</td>
<td>GC操作花费的总时间。</td>
</tr>
<tr>
<td>NGCMN</td>
<td>新生代最小空间容量，单位KB。</td>
</tr>
<tr>
<td>NGCMX</td>
<td>新生代最大空间容量，单位KB。</td>
</tr>
<tr>
<td>NGC</td>
<td>新生代当前空间容量，单位KB。</td>
</tr>
<tr>
<td>OGCMN</td>
<td>老年代最小空间容量，单位KB。</td>
</tr>
<tr>
<td>OGCMX</td>
<td>老年代最大空间容量，单位KB。</td>
</tr>
<tr>
<td>OGC</td>
<td>老年代当前空间容量制，单位KB。</td>
</tr>
<tr>
<td>PGCMN</td>
<td>持久代最小空间容量，单位KB。</td>
</tr>
<tr>
<td>PGCMX</td>
<td>持久代最大空间容量，单位KB。</td>
</tr>
<tr>
<td>PGC</td>
<td>持久代当前空间容量，单位KB。</td>
</tr>
<tr>
<td>PC</td>
<td>持久代当前空间大小，单位KB</td>
</tr>
<tr>
<td>PU</td>
<td>持久代当前已用空间大小，单位KB</td>
</tr>
<tr>
<td>LGCC</td>
<td>最后一次GC发生的原因</td>
</tr>
<tr>
<td>GCC</td>
<td>当前GC发生的原因</td>
</tr>
<tr>
<td>TT</td>
<td>老年化阈值。被移动到老年代之前，在新生代空存活的次数。</td>
</tr>
<tr>
<td>MTT</td>
<td>最大老年化阈值。被移动到老年代之前，在新生代空存活的次数。</td>
</tr>
<tr>
<td>DSS</td>
<td>幸存者区所需空间大小，单位KB。</td>
</tr>
</tbody>
</table>
<ul>
<li>-verbosegc</li>
</ul>
<p>-verbosegc的可用参数如下：</p>
<ul>
<li>-XX:+PrintGCDetails</li>
<li>-XX:+PrintGCTimeStamps</li>
<li>-XX:+PrintHeapAtGC</li>
<li>-XX:+PrintGCDateStamps</li>
</ul>
<p>GC的格式如下：</p>
<pre><code>[GC [&lt;collector&gt;: &lt;starting occupancy1&gt; -&gt; &lt;ending occupancy1&gt;, &lt;pause time1&gt; secs] &lt;starting occupancy3&gt; -&gt; &lt;ending occupancy3&gt;, &lt;pause time3&gt; secs]
</code></pre><table>
<thead>
<tr>
<th>collector</th>
<th>minor gc使用的收集器的名字</th>
</tr>
</thead>
<tbody>
<tr>
<td>starting occupancy1</td>
<td>GC执行前新生代空间大小。</td>
</tr>
<tr>
<td>ending occupancy1</td>
<td>GC执行后新生代空间大小。</td>
</tr>
<tr>
<td>pause time1</td>
<td>因为执行minor GC，Java应用暂停的时间。</td>
</tr>
<tr>
<td>starting occupancy3</td>
<td>GC执行前堆区域总大小</td>
</tr>
<tr>
<td>ending occupancy3</td>
<td>GC执行后堆区域总大小</td>
</tr>
<tr>
<td>pause time3</td>
<td>Java应用由于执行堆空间GC（包括major GC）而停止的时间。</td>
</tr>
</tbody>
</table>
<p>真实环境下的例子如下：</p>
<pre><code>[GC (CMS Final Remark) [ParNew: 9496241K-&gt;543569K(12902400K), 0.5521501 secs] 9496241K-&gt;543569K(74833920K), 0.5522263 secs] [Times: user=2.09 sys=0.19, real=0.56 secs]
</code></pre><p>别的监控工具还有(Java) VisualVM  + Visual GC和<a href="https://h20392.www2.hpe.com/portal/swdepot/displayProductInfo.do?productNumber=HPJMETER" target="_blank" rel="external">HPJMeter</a>。</p>
<h3 id="分析结果"><a href="#分析结果" class="headerlink" title="分析结果"></a>分析结果</h3><p>如果结果表明执行GC的时间只有0.1-0.3s，那么就没有必要浪费时间来进行优化，如果是1s以上，那么就非常有必要了。</p>
<p>如果需要GC优化，那么就要调整GC类型和内存空间了。</p>
<p>一般内存空间与GC执行次数和GC执行时间的关系如下：</p>
<ul>
<li>如果是大内存空间，那么就会减少GC执行次数并且增加GC执行时间。</li>
<li>如果是小内存空间，那么就会减小GC执行时间并且增加GC执行次数。</li>
</ul>
<p>一般优化GC比较重要的参数有堆内存大小，XX:NewRatio的大小，使用的GC类型。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/09/13/javaGC/" data-id="ciuakuqmp00026zonlpos2d3n" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/java/">java</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-system" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/09/02/system/" class="article-date">
  <time datetime="2016-09-02T01:32:59.000Z" itemprop="datePublished">2016-09-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/09/02/system/">一些系统相关问题的定位</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="系统相关"><a href="#系统相关" class="headerlink" title="系统相关"></a>系统相关</h1><h2 id="I-O性能"><a href="#I-O性能" class="headerlink" title="I/O性能"></a>I/O性能</h2><ul>
<li><p>查看I/O：</p>
<pre><code>iostat -xz 1
</code></pre></li>
</ul>
<h2 id="网络监测"><a href="#网络监测" class="headerlink" title="网络监测"></a>网络监测</h2><ul>
<li><p>查看网络sar(System Activity Reporter)</p>
<pre><code>sar –n DEV 1
</code></pre></li>
</ul>
<p>如果“rxkB/s”和“txkB/s”两种相加超过100MB的话，说明网络已经接近饱和了。</p>
<h2 id="内存相关"><a href="#内存相关" class="headerlink" title="内存相关"></a>内存相关</h2><ul>
<li><p>查看内存占用情况：</p>
<pre><code>free -g
</code></pre></li>
</ul>
<h2 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h2><ul>
<li><p>查看CPU负载：</p>
<pre><code>mpstat -P ALL 2
</code></pre></li>
<li><p>查看磁盘IO情况及CPU负载：</p>
<pre><code>vmstat 2
</code></pre></li>
</ul>
<h2 id="测试上下文切换次数"><a href="#测试上下文切换次数" class="headerlink" title="测试上下文切换次数"></a>测试上下文切换次数</h2><pre><code>vmstat 1
</code></pre><p>其中CS(Content Switch)表示上下文切换次数。如果是java程序，那么可以dump线程的一些信息来查看上下午切换。</p>
<pre><code>jstat 777 &gt; /home/cds
grep java.lang.Thread.State /home/cds | awk &apos;{print $2$3$4$5}&apos; | sort | uniq -c
</code></pre><h2 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h2><ul>
<li><p>查看进程树：</p>
<pre><code>ps axf
</code></pre></li>
<li><p>查看进程详细信息：</p>
<pre><code>ps aux
</code></pre></li>
<li><p>查看进程：</p>
<pre><code>top
</code></pre></li>
</ul>
<h2 id="文件相关"><a href="#文件相关" class="headerlink" title="文件相关"></a>文件相关</h2><ul>
<li><p>查看系统允许打开的最大文件数：</p>
<pre><code>cat /proc/sys/fs/file-max
</code></pre></li>
<li><p>查看每个用户允许打开的最大文件数：ulimit -a，当然如果要修改这个值，需要修改/etc/security/limits.conf这个配置文件。</p>
</li>
<li><p>查出每个进程占用的文件数量：</p>
<pre><code>lsof -p 12 | wc -l
</code></pre></li>
<li><p>总共打开文件数：</p>
<pre><code>lsof -n | wc -l
</code></pre></li>
<li><p>显示使用fd为4的进程：</p>
<pre><code>lsof -d 4
</code></pre></li>
<li><p>显示开启文件abc.txt的进程：</p>
<pre><code>lsof abc.txt
</code></pre></li>
<li><p>显示使用22端口的进程：</p>
<pre><code>lsof -i:22
</code></pre></li>
<li><p>显示使用tcp协议的22端口的进程：</p>
<pre><code>lsof -i tcp:22
</code></pre></li>
<li><p>网络相关的文件数：</p>
<pre><code>lsof -n -i  | wc -l
</code></pre></li>
</ul>
<h2 id="网络连接相关"><a href="#网络连接相关" class="headerlink" title="网络连接相关"></a>网络连接相关</h2><ul>
<li><p>网络连接数：</p>
<pre><code>netstat -ant | wc -l
</code></pre></li>
<li><p>端口号是80的网络连接数：</p>
<pre><code>netstat -ant | grep &quot;:80&quot; | wc -l
</code></pre></li>
<li><p>查看端口号是2181的各种状态的连接数：</p>
<pre><code>netstat -ant | grep &quot;:2181&quot; | awk &apos;{print $6}&apos; | sort | uniq -c  | sort -nr
</code></pre></li>
<li><p>所有的网络连接数，按状态排序：</p>
<pre><code>netstat -n | awk &apos;/^tcp/ {++S[$NF]} END {for(a in S) print S[a],a}&apos; | sort -nr
</code></pre></li>
<li><p>所有打开文件数，按进程PID排序：</p>
<pre><code>lsof -n | awk &apos;{print $2}&apos; | sort -n | uniq -c | sort -nr | more
</code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/09/02/system/" data-id="ciuakuqmv00056zon0d3hhwp6" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/System/">System</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-GPU-1" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/07/22/GPU-1/" class="article-date">
  <time datetime="2016-07-22T08:51:59.000Z" itemprop="datePublished">2016-07-22</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/GPU/">GPU</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/07/22/GPU-1/">GPU学习</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>实验环境：<br>系统是Ubuntu，cuda的版本是7.5。</p>
<p>具体怎么搭建还是参考官方文档<a href="http://docs.nvidia.com/cuda/index.html#axzz4DzlUApap" target="_blank" rel="external">documents</a></p>
<h2 id="1、Introduction"><a href="#1、Introduction" class="headerlink" title="1、Introduction"></a>1、Introduction</h2><h3 id="1、1-From-Graphics-Processing-to-General-Purpose-Parallel-Computing"><a href="#1、1-From-Graphics-Processing-to-General-Purpose-Parallel-Computing" class="headerlink" title="1、1 From Graphics Processing to General Purpose Parallel Computing"></a>1、1 From Graphics Processing to General Purpose Parallel Computing</h3><p>由于市场对实时性、3D高清图像的无限制需求的驱动，可编程的GPU(Graphic Processor Unit)已经发展成为一个高度并行的、多线程、多core的处理器。拥有大计算功率和高网络带宽。如下图所示：</p>
<p>图1对比了cpu和GPU每秒的浮点运算，图2对比了cpu和GPU的网络带宽。</p>
<p><img src="http://docs.nvidia.com/cuda/cuda-c-programming-guide/graphics/floating-point-operations-per-second.png" alt="Figure 1"></p>
<p><img src="http://docs.nvidia.com/cuda/cuda-c-programming-guide/graphics/memory-bandwidth.png" alt="Figure 2"></p>
<p>CPU和GPU的浮点运算的差异性原因在于GPU是专门用于计算密集型的(compute-intensive)和高度并行的计算，这也是图像渲染的特点。这样的设计可以使用更多的晶体管来专注于数据处理而不是数据缓存和流程控制。如图3所示：</p>
<p><img src="http://docs.nvidia.com/cuda/cuda-c-programming-guide/graphics/gpu-devotes-more-transistors-to-data-processing.png" alt="Figure 3"></p>
<p>更特殊的是，GPU是更适用于处理能够数据并行计算的问题。同样的程序可以并行的在多个数据单元上(data element)执行，这样的程序一般是高计算密度，也就是计算操作和内存操作的比值比价大。</p>
<p>因为每个数据单元执行同样的程序，所以对于复杂的流程控制操作并不太需要。因为计算密度比较高，所以内存访问的延迟会隐藏在计算中而不是大数据缓存中。</p>
<p>数据并行操作把数据单元映射到并行处理的线程中。许多处理大数据集的应用都可以了使用数据并行编程模型来加速计算。在3D模型渲染中，大量的像素点集被映射到并行线程中。同样的，图像和视频处理的应用中，比如渲染图像的后期处理，视频的编解码，图像缩放，立体视觉和模式识别中可以把图像块和像素映射到并行处理线程中。实际上，在图像渲染和处理领域外的很多算法都可以用数据并行来处理。比如一般的信号处理和物理模拟计算金融学和计算生物学。</p>
<h3 id="1-2-CUDA：A-General-Purpose-Parallel-Computing-Platform-and-Programming-Model"><a href="#1-2-CUDA：A-General-Purpose-Parallel-Computing-Platform-and-Programming-Model" class="headerlink" title="1.2 CUDA：A General-Purpose Parallel Computing Platform and Programming Model"></a>1.2 CUDA：A General-Purpose Parallel Computing Platform and Programming Model</h3><p>在2006年11月份，NVIDIA引入了CUDA，一个通用的并行计算框架和编程模型来提升NVIDIA的GPU的并行计算引擎，用来解决许多复杂的计算问题并且比CPU更有效。</p>
<p>CUDA是一个允许开发者使用C语言或者更高级的语言的软件开发环境，如下图4所示，别的语言，别的应用编程接口或者直接的方法调用都是支持的。</p>
<p><img src="http://docs.nvidia.com/cuda/cuda-c-programming-guide/graphics/gpu-computing-applications.png" alt="Figure 4"></p>
<h3 id="1-3-A-Scalable-Programming-Model"><a href="#1-3-A-Scalable-Programming-Model" class="headerlink" title="1.3 A Scalable Programming Model"></a>1.3 A Scalable Programming Model</h3><p>多核CPU和GPU的到来意味着主流处理芯片都是并行处理系统。更远的说，这也是扩展了摩尔定律。<br>现在的挑战是开发应用软件来显式的扩展并发度，来利用不断增长处理核心数量。比如3D图像应用利用多核GPU显式的提升了并行度。</p>
<p>CUDA并行模型的设计就是用来给哪些熟悉标准的编程语言比如C的编程人员很低的学习曲线。</p>
<p>CUDA内部的核心有三个概念：</p>
<ul>
<li>分层的线程组(a hierarchy of thread groups)</li>
<li>共享内存( shared memories)</li>
<li>栅栏同步(barrier synchronization)</li>
</ul>
<p>这样暴露给编程人员的是一个很小的语言扩展集合。</p>
<p>这几个抽象概念提供了把细粒度的数据并行和线程并行嵌入到粗粒度的数据并行和任务并行。我们会引导程序员把问题分割成粗粒度的子任务，每个子任务都可以独立并行的在线程块中运行，并且每个子任务都可以在所有的并发的线程块中合作的解决。</p>
<p>这样的分解保留了语言的表达力，通过允许线程合作的解决子任务，同时可以自动扩展。<br>确实的，线程中的每一个块都是可以通过多核GPU来调度，调度的顺序可以是任何顺序，比如并发的，比如顺序的。那么一个编译好的CUDA程序可以执行在任何数量的多核处理器，如图5所示，而且只有运行时系统才需要知道物理处理器核心的数量。</p>
<p><img src="http://docs.nvidia.com/cuda/cuda-c-programming-guide/graphics/automatic-scalability.png" alt="Figure 5"></p>
<p>GPU建立在一组多处理器（SMX，Streaming Multiprocessors）附近。<br>一个SMX的配置：</p>
<ul>
<li>192 cores（都是SIMT cores（Single Instruction Multiple Threads） and 64k registers,GPU中的SIMT对应于CPU中的SIMD（Single Instruction Multiple Data）</li>
<li>64KB of shared memory / L1 cache</li>
<li>8KB cache for constants</li>
<li>48KB texture cache for read-only arrays</li>
<li>up to 2K threads per SMX</li>
</ul>
<p>每个multi-thread程序的execution kernel instance（kernel定义见下一节,instance指block）在一个SMX上执行，一个多线程程序会分配到blocks of threads（每个block中负责一部分线程）中独立执行。所以GPU中的处理器越多执行越快（因为如果SMX不够给每个kernel instance分配一个，就要几个kernel抢一个SMX了）。具体来讲，如果SMX上有足够寄存器和内存（后面会讲到，shared memory），就多个kernel instance在一个SMX上执行，否则放到队列里等。</p>
<p>GPU工作原理：首先通过主接口读取中央处理器指令，GigaThread引擎从系统内存中获取特定的数据并拷贝到显存中，为显存控制器提供数据存取所需的高带宽。GigaThread引擎随后为各个SMX创建和分派线程块（warp, 详细介绍见SIMT架构或者CUDA系列学习（二）），SMX则将多个Warp调度到各CUDA核心以及其他执行单元。在图形流水线出现工作超载的时候，GigaThread引擎还负责进行工作的重新分配。</p>
<h2 id="2、Programming-Model"><a href="#2、Programming-Model" class="headerlink" title="2、Programming Model"></a>2、Programming Model</h2><p>这一节主要介绍CUDA编程模型背后的主要概念。用C语言来描述，更多的CUDA c接口扩展描述可以参考<a href="http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#programming-interface" target="_blank" rel="external">Programming Interface</a></p>
<h3 id="2-1-Kernels"><a href="#2-1-Kernels" class="headerlink" title="2.1 Kernels"></a>2.1 Kernels</h3><p>CUDA C 通过运行程序员定义C的函数，这样就扩展了C，我们称之为Kernels, Kernels被调用时<br>就会在N个不同的CUDA线程中执行N次(一个CUDA线程执行一次，那么一共就是次)。普通的C函数都是执行一次。</p>
<p>kernel用<strong>global</strong>这个声明符号来定义，CUDA线程执行给定的kernel的调用的数据通过new&lt;&lt;&lt;…&gt;&gt;&gt;来指定(see <a href="http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#c-language-extensions" target="_blank" rel="external">C Language Extensions</a>)。</p>
<p>每个执行kernel的线程给定一个唯一的线程ID，可以通过在kernel中内置的threaIdx变量来获取。</p>
<p>接下来的代码求两个长度为N的向量的和，并且把结果存储在向量C中。</p>
<pre><code>// Kernel definition
__global__ void VecAdd(float* A, float* B, float* C)
{ int i = threadIdx.x;
  C[i] = A[i] + B[i];
}
int main()
{
  ...
  // Kernel invocation with N threads
  VecAdd&lt;&lt;&lt;1, N&gt;&gt;&gt;(A, B, C);
  ...
}
</code></pre><p>这里N个线程中的每个都执行VecAdd()，并且是向量中的其中一对的和。</p>
<h3 id="2-2-Thread-Hierarchy"><a href="#2-2-Thread-Hierarchy" class="headerlink" title="2.2 Thread Hierarchy"></a>2.2 Thread Hierarchy</h3><p>为了方便起见，threadIdx是一个3维(3-component)的向量,那么线程就可以用一维、二维、三维的线程索引来标记，组成了一维、二维、三维的线程块。这样就提供了一个自然的方式来计算向量、矩阵、卷的元素。</p>
<p>线程的索引和线程的ID彼此之间相关：对于一个一维的块，他们是一样的，对于两维的大小是(Dx,Dy)的块,线程索引(x,y)的线程ID就是(x + yDx);对于三维的大小是(Dx,Dy,Dz)的块 ，线程索引(x,y,z)的线程ID就是(x + yDx + zDxDy)。</p>
<p>下面的例子就是相加大小是N*N的矩阵A和矩阵B，然后存入矩阵C。</p>
<pre><code>// Kernel definition
__global__ void MatAdd(float A[N][N], float B[N][N], float C[N][N])
{
  int i = threadIdx.x;
  int j = threadIdx.y;
  C[i][j] = A[i][j] + B[i][j];
  } int main()
  {
    ... // Kernel invocation with one block of N * N * 1 threads
    int numBlocks = 1;
    dim3 threadsPerBlock(N, N);
    MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A, B, C);
    ...
  }
</code></pre><p>对于每个块的线程数有个限制，因为一个块的所有线程应该都在同一个处理器核，并且共享处理器核上的有限的内存资源。在当前的GPU，一个线程块可以包含1024个线程。</p>
<p>不管怎么样，一个kernel可以在多个等大小(equally-shaped)的线程块中执行，所以线程的总量等于每个线程块中的线程总量*线程块数量。</p>
<p>线程块可以组成一维、二维、三维的grid，如图六所示。在grid中的线程块数量一般由需要处理的数据的大小或者是系统处理器数量决定的。</p>
<p><img src="http://docs.nvidia.com/cuda/cuda-c-programming-guide/graphics/grid-of-thread-blocks.png" alt="Figure 6"></p>
<p>每个块的线程数量和grid中块的数量由&lt;&lt;&lt;…&gt;&gt;&gt;这样的语法指定，可以是int，或者dim3。二维的块或者grid在上面的例子代码有说明。</p>
<p>grid中的每个块可以由一维、二维、三维的索引指定，这些索引是在kernel中通过内置的blockIdx获取，线程块的纬度可以在kernel中通过内置的blockDim变量获取。</p>
<p>扩展前面的MatAdd()例子来处理多个块，代码如下：</p>
<pre><code>// Kernel definition
__global__ void MatAdd(float A[N][N], float B[N][N],
  float C[N][N])
  {     
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;
    if (i &lt; N &amp;&amp; j &lt; N)
    C[i][j] = A[i][j] + B[i][j];
  }

  int main()
  {
    ...
    // Kernel invocation
    dim3 threadsPerBlock(16, 16);
    dim3 numBlocks(N / threadsPerBlock.x, N / threadsPerBlock.y);
    MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A, B, C);
    ...
  }
</code></pre><p>一个16*16大小的线程块(256个线程)是一个正常的选择,虽然在这个例子中是任意的大小。足够的线程块，就可以每个每个矩阵元素分配一个线程，这样就可以创建一个grid。</p>
<p>简单的说，这个例子假设每个维度中的grid中的线程数量最终分割成同一个维度的线程块中的线程数，虽然在这里例子中并不是这样的。</p>
<p>线程块需要独立的执行：它们可以任意顺序的执行，并行或者按顺序。独立性也就允许了线程块可以在不同的处理器核上按任意顺序调度。如图5所示，这样也允许了程序员可以写在不同的处理核上可以扩展的代码。</p>
<p>同一个线程块中的线程中的线程可以通过一些共享的内存中的数据来合作处理，也可以协调线程间的内存访问来同步线程。更精确的说你可以在kernel代码中调用<strong>syncthreads()这个内部函数来同步操作。\</strong>syncthreads()的功能就像是栅栏(barrier),也就是说线程块中的所有线程除非被允许执行，否则就一直等待下去。<a href="http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#shared-memory" target="_blank" rel="external"> Shared Memory</a>给出了如何使用共享内存的例子。</p>
<p>为了有限的合作，共享内存必须是每个处理器的低延迟区域(比如L1缓存),而且__syncthreads()是轻量级的操作。</p>
<h3 id="Memory-Hierarchy"><a href="#Memory-Hierarchy" class="headerlink" title="Memory Hierarchy"></a>Memory Hierarchy</h3><p>CUDA的线程可以在执行过程中从不同的内存空间中访问数据，如图7所示。每个线程都有自己的私有本地内存。每个线程块都有自己内部线程可见的共享内存，并且伴随着线程块的生命周期。所有的线程都可以访问同样的全局内存。</p>
<p>还有两个额外的所有线程都可以访问的只读内存空间：常量区(the constant) 和纹理内存空间(texture memory spaces)。全局、常量区、纹理内存空间都是为不同的用处优化过的(see <a href="http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses" target="_blank" rel="external"> Device Memory Accesses</a>。纹理内存还提供了不同的访问模式，就跟数据过滤一样，一些具体的数据格式可以参考<a href="http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#texture-and-surface-memory" target="_blank" rel="external">Texture and Surface Memory</a>。</p>
<p>内存全局区、常量区、纹理区空间在应用程序的kernel运行时就持久化了。</p>
<p><img src="http://docs.nvidia.com/cuda/cuda-c-programming-guide/graphics/memory-hierarchy.png" alt="Figure 7"></p>
<h3 id="Heterogeneous-Programming"><a href="#Heterogeneous-Programming" class="headerlink" title="Heterogeneous Programming"></a>Heterogeneous Programming</h3><p>就像图8描述的那样，CUDA编程模型假设CUDA线程在物理上独立的设备上执行，就像是在主机上的协处理器上执行c程序一样。在这个例子中，GPU只执行kernel部分，其它c语言代码在CPU上执行。</p>
<p>CUDA编程模型假设主机(host)和设备(device)维护了在DRAM中自己独立的空间，也就是说主机内存和设备内存是相互独立的。因为一个CUDA的程序管理全局内存、常量区内存、纹理区内存，通过调用CUDA runtime让它们对kernels可见，见<a href="http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#programming-interface" target="_blank" rel="external">Programming Interface</a>。这也包含了设备内存数据在主机和设备上转移时内存的分配和释放。</p>
<p><img src="http://docs.nvidia.com/cuda/cuda-c-programming-guide/graphics/heterogeneous-programming.png" alt="Figure 8"></p>
<h3 id="Compute-Capability"><a href="#Compute-Capability" class="headerlink" title="Compute Capability"></a>Compute Capability</h3><p>一块GPU设备的计算能力是由版本号决定的，有时又称之为SM version。这个版本号标识了GPU设备能够支持的特性，并且应用程序在运行时来决定当前GPU硬件哪些特性或者指令被使用。</p>
<p>计算能力由一个主修订号X和一个最小的修订号组成，写成：X.Y。</p>
<p>拥有同样的主修订号的设备有同样的核心架构。比如主修订号5表示设备是基于Maxwell架构，3表示Kepler架构，2表示Fermi架构，1表示Tesla架构。</p>
<p>最小的修订号表示在这个核心架构上的一些持续改进，包含了一些新的特性。</p>
<p><a href="http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#cuda-enabled-gpus" target="_blank" rel="external">CUDA-Enabled GPUs</a>列出了所有的支持CUDA的设备和它们的计算能力。<a href="http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capabilities" target="_blank" rel="external"> Compute Capabilities</a>给出了计算能力的技术说明。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/07/22/GPU-1/" data-id="ciuakuqmm00016zonyz6iz8ka" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GPU/">GPU</a></li></ul>

    </footer>
  </div>
  
</article>


  

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/GPU/">GPU</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/GPU/">GPU</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/System/">System</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/">java</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/GPU/" style="font-size: 10px;">GPU</a> <a href="/tags/System/" style="font-size: 10px;">System</a> <a href="/tags/java/" style="font-size: 10px;">java</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/10/01/hashmap/">hashmap</a>
          </li>
        
          <li>
            <a href="/2016/09/13/javaGC/">GC调优</a>
          </li>
        
          <li>
            <a href="/2016/09/02/system/">一些系统相关问题的定位</a>
          </li>
        
          <li>
            <a href="/2016/07/22/GPU-1/">GPU学习</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>